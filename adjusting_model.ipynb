{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "adjusting-model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEHNaGqq-KVf",
        "colab_type": "text"
      },
      "source": [
        "# Conjuntos dos dados\n",
        "Normalmente os conjuntos de dados são divididos em 3 subconjuntos que você pode ver a seguir:\n",
        "\n",
        "- **Conjunto de treinamento**: é o subconjunto dos dados do qual o algoritmo de aprendizado de máquina descobre, ou \"aprende\", os relacionamentos entre os recursos e a variável de destino. É o maior subconjunto de dados;\n",
        "- **Conjunto de validação**: é o subconjunto dos dados que serve para realizar as validações iniciais durante a aprendizagem do modelo. É o menor subconjunto de dados;\n",
        "- **Conjunto de teste**: é o subconjunto dos dados que serve para dar uma estimativa final do desempenho do modelo, após esse ter sido treinado e validado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I45hxP-d-LBz",
        "colab_type": "text"
      },
      "source": [
        "# Viés e Variância\n",
        "Viés consiste em um erro sistemático, sendo uma distorção aleatória de uma estatística, como resultado do processo de amostragem. Consiste na diferença entre o valor médio de um estimador estatístico e o valor que pretende estimar. Isso ocorre quando os dados de treinamento diz $X$, porém o conjunto de dados de validação diz $Y$, ou seja, o conjunto de dados de treinamento não são uma boa representação da realidade ou eles refletem preconceitos existentes. O problema de se ter um viés alto é chamado de _underfitting_ (sub-ajuste).\n",
        "\n",
        "Variância é uma medida de dispersão que mostra o quão distante cada valor desse conjunto está do valor central (média). Uma alta variância nos quer dizer que o nosso modelo está memorizando os valores do conjunto de treinamento, se tornando ineficaz para rpever novos resultados. O problema de se ter uma variância alta é chamado de _overfitting_ (sobre-ajuste ou super-ajuste).\n",
        "\n",
        "<img src=\"https://cdn-images-1.medium.com/max/1600/1*1YsNYT27ZgzmaHf2UsHJzw.png\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqQGVCgU-Nuc",
        "colab_type": "text"
      },
      "source": [
        "## Overfitting\n",
        "Como dito anteriormente, _overfitting_ (sobre-ajuste ou super-ajuste) é quando temos uma variância alta. Uma das maneiras mais básicas que temos de reduzir esse problema é aumentando a quantidade de dados de treinamento, sendo que isso pode ser uma tarefa custosa dependendo do seu contexto. Outra maneira seria reduzir o tamanho da nossa rede, sendo que redes grandes têm o potencial de serem mais poderosas do que redes pequenas.\n",
        "\n",
        "<img src=\"https://cdn-images-1.medium.com/max/510/1*9wkNM_qH6BdqPw5O31x6eg.jpeg\" />\n",
        "\n",
        "Felizmente existem as conhecidas **técnicas de regularização**, que servem justamente para diminuirmos esse nosso problema de _overfitting_.\n",
        "\n",
        "### Técnicas de regularização\n",
        "Abaixo coloco algumas técnicas de regularização que podem serem usadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXIVGMH6BxUL",
        "colab_type": "text"
      },
      "source": [
        "#### Regularização L2\n",
        "Também conhecida como **decaimento de peso**, consiste em adicionar um termo extra (chamado de termo de regularização) à função de custo. Iremos chamade $J_{0}$ a função de custo original e não regularizada. Dessa forma, adicionando o termo de regularização, temos:\n",
        "\n",
        "\\begin{equation}\n",
        "    J(w,b) = J_{0} + \\frac{\\lambda}{2m} \\|w\\|_{2}^{2} \\\\\n",
        "    \\|w\\|_{2}^{2} = \\sum_{j=1}^{n_{x}} w_{j}^{2} = w^{t} \\cdot w\n",
        "\\end{equation}\n",
        "\n",
        "Intuitivamente, o efeito da regularização é fazer com que a rede prefira aprender pequenos pesos, sendo todas as outras coisas iguais. Pesos grandes só serão permitidos se melhorarem consideravelmente a primeira parte da função de custo. Dito de outra forma, a regularização pode ser vista como uma forma de se comprometer entre encontrar pequenos pesos e minimizar a função de custo original. A importância relativa dos dois elementos do compromisso depende do valor de $\\lambda$:\n",
        "\n",
        "- Quando $\\lambda$ é pequeno, preferimos minimizar a função de custo original;\n",
        "- Quando $\\lambda$ é grande, preferimos pesos pequenos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2786nG54EVjp",
        "colab_type": "text"
      },
      "source": [
        "#### Regularização L1\n",
        "Nesta abordagem, modificamos a função de custo não regularizada, adicionando a soma dos valores absolutos dos pesos:\n",
        "\n",
        "\\begin{equation}\n",
        "    J(w,b) = J_{0} + \\frac{\\lambda}{m} \\sum_{j=1}^{n_{x}} |w_{j}|\n",
        "\\end{equation}\n",
        "\n",
        "Intuitivamente, isso é semelhante à regularização L2, penalizando grandes pesos e tendendo a fazer com que a rede prefira pequenos pesos. Naturalmente, o termo de regularização L1 não é o mesmo que o termo de regularização L2 e, portanto, não devemos esperar obter exatamente o mesmo comportamento.\n",
        "\n",
        "Em ambas as expressões, o efeito da regularização é diminuir os pesos. Isso está de acordo com a nossa intuição de que ambos os tipos de regularização penalizam grandes pesos. Mas a maneira como os pesos diminuem é diferente. Na regularização L1, os pesos diminuem em uma quantidade constante para $0$. Na regularização L2, os pesos diminuem em um valor proporcional a $w$. E assim, quando um peso específico tem uma grande magnitude, a regularização L1 reduz o peso muito menos do que a regularização L2. Em contraste, quando $|w|$ é pequena, a regularização L1 reduz o peso muito mais do que a regularização L2. O resultado é que a regularização L1 tende a concentrar o peso da rede em um número relativamente pequeno de conexões de alta importância, enquanto os outros pesos são direcionados para zero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IvMLFn-Fvnx",
        "colab_type": "text"
      },
      "source": [
        "#### Dropout\n",
        "Ao contrário da Regularização L1 e L2, o Dropout não depende da modificação da função de custo, em vez disso modificamos a própria rede.\n",
        "\n",
        "<img src=\"https://i2.wp.com/deeplearningbook.com.br/wp-content/uploads/2018/07/rede.png?w=310\" />\n",
        "<img src=\"https://i0.wp.com/deeplearningbook.com.br/wp-content/uploads/2018/07/rede2.png?w=310\" />\n",
        "\n",
        "1. Começamos por eliminar aleatoriamente (e temporariamente) alguns dos neurônios ocultos na rede, deixando os neurônios de entrada e saída intocados;\n",
        "1. Nós encaminhamos para frente a entrada x através da rede modificada, e depois retropropagamos o resultado, também através da rede modificada;\n",
        "1. Depois de fazer isso em um mini-lote de exemplos, atualizamos os pesos e vieses apropriados;\n",
        "1. Em seguida, restauramos os neurônios removidos e repetimos todo o processo.\n",
        "\n",
        "Ao repetir esse processo várias vezes, nossa rede aprenderá um conjunto de pesos e vieses. Naturalmente, esses pesos e vieses terão sido aprendidos sob condições em que parte dos neurônios ocultos foram descartados. Quando realmente executamos a rede completa, isso significa que mais neurônios ocultos estarão ativos. Para compensar isso, reduzimos pela metade os pesos que saem dos neurônios ocultos.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7XWErY0BwsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}