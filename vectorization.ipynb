{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vectorization.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "PiQUxdODzXB0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Vectorização\n",
        "A vetorização é a arte de livrar-se de laços de repetição explícitos em seu código, isso é uma forma de você gerar economia em deep learning na prática.\n",
        "\n",
        "Em regressão logística, nós temos que calcular $z = w^{t} \\times x + b$, onde $w$ e $x$ são vetores (lembrando que $n_{x}$ é o tamanho da entrada).\n",
        "\n",
        "\\begin{equation}\n",
        "w \\in \\mathbb{R}^{n_{x}} =\n",
        "  \\begin{bmatrix}\n",
        "    \\vdots \\\\\n",
        "    \\vdots \\\\\n",
        "  \\end{bmatrix}\n",
        "x \\in \\mathbb{R}^{n_{x}} =\n",
        "  \\begin{bmatrix}\n",
        "    \\vdots \\\\\n",
        "    \\vdots \\\\\n",
        "  \\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "Em uma implementação não vetorizada, teriamos algo como:\n",
        "```py\n",
        "z = 0\n",
        "for i in range(n_x):\n",
        "    z += w[i] * x[i]\n",
        "z += b\n",
        "```\n",
        "\n",
        "Já em uma implementação vetorizada, teriamos algo como (**np** é a biblioteca [*numpy*](https://www.numpy.org/)):\n",
        "```py\n",
        "z = np.dot(w, x) + b\n",
        "```\n",
        "\n",
        "Para ter uma melhor noção de desempenho, execute as celulas a seguir."
      ]
    },
    {
      "metadata": {
        "id": "p-EO1bWO2h51",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "a = np.random.rand(1000000)\n",
        "b = np.random.rand(1000000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fPfGmdA22nhE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "dd5da2ca-60ed-49fd-9f04-327e7788487e"
      },
      "cell_type": "code",
      "source": [
        "# Não vetorizado\n",
        "c = 0\n",
        "\n",
        "tic = time.time()\n",
        "for i in range(1000000):\n",
        "  c += a[i] * b[i]\n",
        "toc = time.time()\n",
        "\n",
        "print(\"c: \" + str(c))\n",
        "print(\"For loop: \" + str(1000*(toc-tic)) + \"ms\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c: 250150.75176781975\n",
            "For loop: 480.67474365234375ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xLKLsLN929dr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "74c92fdf-d7c2-4434-8b2f-670f16050251"
      },
      "cell_type": "code",
      "source": [
        "# Vetorizado\n",
        "tic = time.time()\n",
        "c = np.dot(a,b)\n",
        "toc = time.time()\n",
        "\n",
        "print(\"c: \" + str(c))\n",
        "print(\"Vetorized version: \" + str(1000*(toc-tic)) + \"ms\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c: 250150.75176783197\n",
            "Vetorized version: 1.888275146484375ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OTf1JXDO3lGb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}